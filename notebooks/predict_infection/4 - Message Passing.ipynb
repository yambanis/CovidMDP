{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../../src/models\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import Parallel, delayed\n",
    "#from tqdm import tqdm\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from actions import city_restrictions\n",
    "\n",
    "prhome = 0.06\n",
    "\n",
    "p_r = {\n",
    "    'home'    :  prhome,\n",
    "    'neighbor':  .1*prhome,\n",
    "    'work'    :  .1*prhome,\n",
    "    'school'  :  .15*prhome,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dataset = pd.read_parquet(\"model_dataset.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_df = pd.read_parquet(\"simulation_results_dataset.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpickle_path = \"../../data/processed/SP_multiGraph_Job_Edu_Level.gpickle\"\n",
    "G = nx.read_gpickle(gpickle_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges = [\n",
    "    (source, target, data['edge_type'])\n",
    "    for source, target, data in G.edges(data=True)\n",
    "]\n",
    "\n",
    "edgelist_df = pd.DataFrame(edges, columns=['source', 'target', 'edge_type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_percolation_states(df, initial_state=0, percolation_one_states=[1, 2], state_column='state'):\n",
    "    return df[state_column].apply(lambda x: 0 if x==initial_state else 1 if x in percolation_one_states else np.nan)\n",
    "\n",
    "def get_percolation_nodes(df):\n",
    "    nodes_percolation = df[['id', 'percolation']].dropna(subset=['percolation'])\n",
    "    nodes_percolation['id'] = nodes_percolation['id'].astype(int)\n",
    "    nodes_percolation = nodes_percolation.set_index('id').to_dict()['percolation']\n",
    "    \n",
    "    return nodes_percolation\n",
    "\n",
    "def get_percolation_edgelist(edgelist_df, nodes_percolation, action):\n",
    "    edgelist_percolation = edgelist_df[\n",
    "        (edgelist_df['target'].isin(nodes_percolation.keys())) &\n",
    "        (edgelist_df['source'].isin(nodes_percolation.keys()))\n",
    "    ].copy()\n",
    "\n",
    "    edgelist_percolation['weight'] = (\n",
    "        (1 - edgelist_percolation['edge_type'].map(city_restrictions[action])) * \n",
    "        edgelist_percolation['edge_type'].map(p_r)\n",
    "    )\n",
    "        \n",
    "    return edgelist_percolation\n",
    "        \n",
    "def message_pass(edgelist_percolation, nodes_percolation):\n",
    "    percolation_graph = nx.from_pandas_edgelist(edgelist_percolation, edge_attr='weight')\n",
    "    adj_matrix = nx.to_scipy_sparse_matrix(percolation_graph, weight='weight')\n",
    "        \n",
    "    initial_estates = np.array([nodes_percolation[n] for n in percolation_graph.nodes()])\n",
    "    \n",
    "    mp1 = adj_matrix @ initial_estates\n",
    "    mp2 = adj_matrix @ mp1\n",
    "    mp3 = adj_matrix @ mp2\n",
    "        \n",
    "    message_passing_df = pd.DataFrame(np.stack([mp1, mp2, mp3, list(percolation_graph.nodes())]).T,\n",
    "                                  columns=['mp1', 'mp2', 'mp3', 'id'])\n",
    "        \n",
    "    return message_passing_df\n",
    "\n",
    "\n",
    "def all_steps_message_passing(res_df, simulation, week, initial_state=0, percolation_one_states=[1, 2]):\n",
    "\n",
    "    sim_df = res_df[res_df['simulation'] == simulation]\n",
    "    sim_week_df = sim_df[sim_df['week'] == week].copy()\n",
    "    action = sim_week_df['action'].iloc[0]\n",
    "\n",
    "    sim_week_df['percolation'] = get_percolation_states(sim_week_df, initial_state, percolation_one_states)\n",
    "    nodes_percolation = get_percolation_nodes(sim_week_df)\n",
    "    edgelist_percolation = get_percolation_edgelist(edgelist_df, nodes_percolation, action)\n",
    "    message_passing_df = message_pass(edgelist_percolation, nodes_percolation)\n",
    "    message_passing_df['week'], message_passing_df['simulation'] = week, simulation\n",
    "\n",
    "    return message_passing_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f26ad4e4d02b4d31abaf1dd5807b1086",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/256 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "message_passing_dfs = Parallel(n_jobs=16)(delayed(all_steps_message_passing)(res_df, simulation, week) \n",
    "                                          for simulation, week in \n",
    "                                          tqdm([(sim, w) for sim in res_df['simulation'].unique() for w in range(1, 17)]))\n",
    "\n",
    "message_passing_final_df = pd.concat(message_passing_dfs)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "message_passing_dfs = [all_steps_message_passing(res_df, simulation, week) \n",
    "                                          for simulation, week in \n",
    "                                          tqdm([(sim, w) for sim in res_df['simulation'].unique() for w in range(1, 17)])]\n",
    "\n",
    "message_passing_final_df = pd.concat(message_passing_dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dataset = pd.merge(\n",
    "    model_dataset,\n",
    "    message_passing_final_df,\n",
    "    on=['id', 'simulation', 'week']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dataset.reset_index(drop=True).to_parquet(\"model_dataset.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-masters]",
   "language": "python",
   "name": "conda-env-.conda-masters-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
