{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../../src/models\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from actions import city_restrictions, costs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from simulate_pandemic import init_infection, spread_infection, lambda_leak_expose, update_population\n",
    "from simulate_pandemic import main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.random import default_rng\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "from joblib import Parallel, delayed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate simulation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_individual_df(week, sim, action, data):\n",
    "    df = pd.DataFrame(data, columns=['id', 'state'])\n",
    "    df['simulation'] = sim\n",
    "    df['week'] = week\n",
    "    df['action'] = action\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_value_counts_df(week, sim, action, data):\n",
    "    df = pd.DataFrame(pd.Series(data[:, 1]).value_counts()).T\n",
    "    df['simulation'] = sim\n",
    "    df['week'] = week\n",
    "    df['action'] = action\n",
    "    df = df.rename(columns = {\n",
    "                              -1 : 'removed',\n",
    "                               0 : 'susceptible',\n",
    "                               1 : 'exposed',\n",
    "                               2 : 'infected',\n",
    "                               3 : 'hospitalized'\n",
    "                              }\n",
    "                  )\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_and_save(policy_number, policy, n_sims, step_size=7, folder='generated_sims/'):\n",
    "    dfs = []\n",
    "    for sim in range(1, n_sims+1):\n",
    "        \n",
    "        sim_name = f'{policy_number}_{sim}'\n",
    "                \n",
    "        data, pop_matrix = main(gpickle_path=gpickle_path,\n",
    "                                p_r=p_r,\n",
    "                                policy=policy,\n",
    "                                disable_tqdm=True,\n",
    "                                days=step_size*len(policy),\n",
    "                                step_size=step_size)\n",
    "        \n",
    "        weeks = (step_size/7) * len(policy)\n",
    "        \n",
    "        weekly_data = [data[i*7] for i in range(int(weeks))]\n",
    "        df = pd.concat([make_individual_df(week, sim_name, action, data)\n",
    "                             for week, (data, action) in enumerate(zip(weekly_data, policy))])\n",
    "        #df.to_parquet(folder + f'{sim_name}.parquet')\n",
    "        dfs += [df]\n",
    "    return dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = default_rng(None)\n",
    "\n",
    "gpickle_path = \"../../data/processed/SP_multiGraph_Job_Edu_Level.gpickle\"\n",
    "\n",
    "prhome = 0.06\n",
    "p_r = {\n",
    "    'home'    :  prhome,\n",
    "    'neighbor':  .1*prhome,\n",
    "    'work'    :  .1*prhome,\n",
    "    'school'  :  .15*prhome,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "costs_keys = list(costs.keys())\n",
    "costs_values = np.array(list(costs.values()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cost Weighted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = (1 - costs_values) / (1 - costs_values).sum()\n",
    "policy = [rng.choice(costs_keys, size=int(364/14),\n",
    "                     replace=True, p=p)\n",
    "          for i in range(16)]\n",
    "\n",
    "assert len(set([tuple(p) for p in policy])) == len(policy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:00<00:00, 101.29it/s]\n"
     ]
    }
   ],
   "source": [
    "n_sims=1\n",
    "res = Parallel(n_jobs=16)(delayed(simulate_and_save)(i, pol, n_sims) \n",
    "                              for i, pol in tqdm(enumerate(policy),\n",
    "                                                 total=len(policy)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_df = pd.concat([r for rr in res for r in rr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23084672, 5)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_df.to_parquet(\"simulation_results_dataset.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add individuals data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "individual_infos = pd.read_feather(\"../../data/interim/work_school_home_sp_esc.feather\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "individual_infos['id'] = individual_infos.index + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_info = pd.merge(\n",
    "    res_df,\n",
    "    individual_infos[['id', 'home', 'school', 'work', 'idade', 'home_id']].astype(float),\n",
    "    on='id'\n",
    ").copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Target (State two weeks from now)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_info['target'] = dataset_info.groupby(['id', 'simulation'])['state'].shift(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "week\n",
       "0     0.000000\n",
       "1     0.000091\n",
       "2     0.000641\n",
       "3     0.001653\n",
       "4     0.003345\n",
       "5     0.005817\n",
       "6     0.009937\n",
       "7     0.015996\n",
       "8     0.024897\n",
       "9     0.036642\n",
       "10    0.051450\n",
       "11    0.069498\n",
       "12    0.093423\n",
       "13    0.124035\n",
       "14    0.158909\n",
       "15    0.195266\n",
       "16    0.231863\n",
       "17    0.268399\n",
       "18    0.302933\n",
       "19    0.335357\n",
       "20    0.363060\n",
       "21    0.385925\n",
       "22    0.405890\n",
       "23    0.423491\n",
       "24    0.438070\n",
       "25    0.450042\n",
       "Name: state, dtype: float64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_info.groupby(['week'])['state'].apply(lambda x: (x == -1).sum() / len(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discarding weeks 17 onwards, due to 30% removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_info = dataset_info[dataset_info['week'] < 17]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_info.target.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_info['target'] = dataset_info['target'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_columns_map(relation_type):\n",
    "    return {\n",
    "        'week': 'actual_week',\n",
    "        -1: f'{relation_type}_removed',\n",
    "        0: f'{relation_type}_susceptible',\n",
    "        1: f'{relation_type}_exposed',\n",
    "        2: f'{relation_type}_infected',\n",
    "        3: f'{relation_type}_hospitalized'\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "home\n",
      "value counts done\n",
      "Pivot Done\n",
      "school\n",
      "value counts done\n",
      "Pivot Done\n",
      "work\n",
      "value counts done\n",
      "Pivot Done\n",
      "home_id\n",
      "value counts done\n",
      "Pivot Done\n"
     ]
    }
   ],
   "source": [
    "resulting_ratios = {}\n",
    "\n",
    "for relation_type in ['home', 'school', 'work', 'home_id']:\n",
    "    print(relation_type)\n",
    "    value_counts_week = (\n",
    "        dataset_info\n",
    "            .groupby(['week', 'simulation', relation_type])['target']\n",
    "            .value_counts(normalize=True)\n",
    "            .reset_index(name='ratio')\n",
    "    )\n",
    "    \n",
    "    print(\"value counts done\")\n",
    "    pivot = (\n",
    "        pd.pivot_table(data=value_counts_week, index=['week', 'simulation', relation_type],\n",
    "                       columns='target', values='ratio', fill_value=0)\n",
    "          .reset_index()\n",
    "          .rename(columns=create_columns_map(relation_type))\n",
    "    )\n",
    "    \n",
    "    print(\"Pivot Done\")\n",
    "   \n",
    "    pivot['week'] = pivot['actual_week'] + 1\n",
    "    \n",
    "    resulting_ratios[relation_type] = pivot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['home', 'school', 'work', 'home_id'])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resulting_ratios.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dataset = dataset_info[(dataset_info['target'].notna()) & (dataset_info['state'] == 0)].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9113703061596584"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_dataset.shape[0] / dataset_info.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dataset = pd.merge(\n",
    "    model_dataset,\n",
    "    resulting_ratios['home'].drop(\"actual_week\", axis=1),\n",
    "    on=['week', 'simulation', 'home']\n",
    ").merge(\n",
    "    resulting_ratios['work'].drop(\"actual_week\", axis=1),\n",
    "    on=['week', 'simulation', 'work']\n",
    ").merge(\n",
    "    resulting_ratios['school'].drop(\"actual_week\", axis=1),\n",
    "    on=['week', 'simulation', 'school']\n",
    ").merge(\n",
    "    resulting_ratios['home_id'].drop(\"actual_week\", axis=1),\n",
    "    on=['week', 'simulation', 'home_id']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dataset['numerical_actions'] = model_dataset['action'].map({\n",
    "    'Unrestricted': 0,\n",
    "    'Social Distancing':1,\n",
    "    'Light Quarantine': 2,\n",
    "    'Hard Quarantine':3,\n",
    "    'Lockdown':4\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Should we consider only target state 1 or any target state different than 0? i.e., the person can be hospitalized, should also count as a one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dataset['binary_target'] = (model_dataset['target'] == 1).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dataset['train_test'] = list(map({True: 'train', False: 'test'}.get, (model_dataset['week'] < 11)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "train_test  week\n",
       "test        11      0.056490\n",
       "            12      0.056132\n",
       "            13      0.052174\n",
       "            14      0.050541\n",
       "            15      0.051214\n",
       "            16      0.045794\n",
       "train       1       0.002479\n",
       "            2       0.003297\n",
       "            3       0.006110\n",
       "            4       0.010690\n",
       "            5       0.016711\n",
       "            6       0.019256\n",
       "            7       0.021885\n",
       "            8       0.027184\n",
       "            9       0.036520\n",
       "            10      0.051222\n",
       "Name: binary_target, dtype: float64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_dataset.groupby(['train_test', 'week'])['binary_target'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dataset.reset_index(drop=True).to_parquet(\"model_dataset.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(431921, 34)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-masters]",
   "language": "python",
   "name": "conda-env-.conda-masters-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
